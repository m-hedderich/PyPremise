{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f3274e0-c1b5-441e-a38a-d89733c5dbdb",
   "metadata": {},
   "source": [
    "# PyPremise Example:  LLM outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c8cd05-fe63-43fb-9c2b-c14c63a1775f",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use PyPremise to analyze how different prompts lead to different outputs from a language model (in this case, OpenAI's GPT-4o-mini).\n",
    "\n",
    "We generate outputs for two prompts, label them, and then use PyPremise to find patterns that distinguish between them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d88699a",
   "metadata": {},
   "source": [
    "We begin by installing the OpenAI python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98590ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac4dda8",
   "metadata": {},
   "source": [
    "Import all the packages we will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e88fc2bd-0e68-4c12-90e4-932e2e550c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from pypremise import Premise, data_loaders\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5924d756",
   "metadata": {},
   "source": [
    "To use GPT-4o-mini, you need an API key. If you don’t have one yet, you can get it from https://platform.openai.com/.\n",
    "\n",
    "Security Tip: Never share your API key or upload it to public code repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020b3ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your own OpenAI API key\n",
    "key = \"sk-...\"  # <-- Make sure to keep this secret\n",
    "client = OpenAI(api_key=key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec580d4-9f58-4560-aeb0-2ba865247265",
   "metadata": {},
   "source": [
    "We define a helper function `llm_call(prompt, seed)` to call GPT-4o-mini.\n",
    "\n",
    "The `seed` is important here: it ensures **reproducibility**, meaning that if you use the same prompt and seed, you’ll get the same output every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1de56eba-f4d8-4350-83ff-9b6d09a001d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(prompt, seed):\n",
    "    \"\"\"\n",
    "    Calls GPT-4o with a specific prompt and seed.\n",
    "    Returns the generated text from the model.\n",
    "    \"\"\"\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        seed=seed,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb0e92d-a7a8-48be-8722-f8db8c6037a8",
   "metadata": {},
   "source": [
    "This is the core function where the experiment happens. Here's the logic:\n",
    "\n",
    "1. Call GPT-4o-mini multiple times with each prompt\n",
    "\n",
    "2. Tokenize the outputs into word lists\n",
    "\n",
    "3. Label them (0 = from prompt1, 1 = from prompt2)\n",
    "\n",
    "4. Use PyPremise to find patterns that differentiate the two classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a63c48e-db46-4247-9044-93aed2302324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(experiment_name, prompt1, prompt2, repetitions):\n",
    "    \"\"\"\n",
    "    Calls the model with two prompts multiple times, labels the results,\n",
    "    and uses PyPremise to find patterns that distinguish them.\n",
    "    \"\"\"\n",
    "    # Generate text instances from both prompts\n",
    "    instances1 = [llm_call(prompt1, i).split(\" \") for i in tqdm(range(repetitions), desc=\"Prompt 1\")]\n",
    "    instances2 = [llm_call(prompt2, i).split(\" \") for i in tqdm(range(repetitions), desc=\"Prompt 2\")]\n",
    "    instances = instances1 + instances2\n",
    "    labels = [0]*repetitions + [1]*repetitions\n",
    "\n",
    "    # Convert to PyPremise input format\n",
    "    premise_instances, _, voc_index_to_token = data_loaders.from_token_lists_and_labels(instances, labels)\n",
    "    premise = Premise(voc_index_to_token=voc_index_to_token)\n",
    "\n",
    "    # Discover patterns\n",
    "    patterns = premise.find_patterns(premise_instances)\n",
    "\n",
    "    # Save results\n",
    "    results = {\n",
    "        \"b_prompt1\": prompt1,\n",
    "        \"b_prompt2\": prompt2,\n",
    "        \"instances1\": instances1,\n",
    "        \"instances2\": instances2,\n",
    "        \"a_patterns\": [str(p) for p in patterns]\n",
    "    }\n",
    "\n",
    "    with open(\"result_\" + experiment_name + \".json\", \"w\") as out_file:\n",
    "        json.dump(results, out_file, sort_keys=True, indent=4)\n",
    "\n",
    "    # Also return patterns for inspection\n",
    "    return patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960a445d",
   "metadata": {},
   "source": [
    "Let’s say we want to understand how GPT-4o-mini talks differently about doctors vs. teachers.\n",
    "\n",
    "We define two prompts that only differ in the profession mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d5843af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = \"Tell a 50 word story about a doctor.\"\n",
    "prompt2 = \"Tell a 50 word story about a teacher.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff517e0",
   "metadata": {},
   "source": [
    "Let’s generate 30 examples from each prompt (for faster testing).\n",
    "\n",
    "You can increase this number later to improve pattern quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b51d239",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompt 1: 100%|██████████| 30/30 [00:56<00:00,  1.88s/it]\n",
      "Prompt 2: 100%|██████████| 30/30 [00:56<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "patterns = run_experiment(\"doctor_vs_teacher\", prompt1, prompt2, repetitions=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90113452",
   "metadata": {},
   "source": [
    "Let’s now look at the top patterns that PyPremise found.\n",
    "Each pattern is a word (or phrase) that strongly correlates with either the doctor or teacher prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f062c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern 1: (Dr.) towards group 0 (Instances: 30 in group 0, 0 in group 1)\n",
      "Pattern 2: (stood) and (before) towards group 1 (Instances: 0 in group 0, 17 in group 1)\n",
      "Pattern 3: (rushed) towards group 0 (Instances: 21 in group 0, 0 in group 1)\n",
      "Pattern 4: (Thompson) towards group 1 (Instances: 0 in group 0, 20 in group 1)\n",
      "Pattern 5: (A) towards group 0 (Instances: 20 in group 0, 1 in group 1)\n",
      "Pattern 6: (through) towards group 0 (Instances: 23 in group 0, 3 in group 1)\n"
     ]
    }
   ],
   "source": [
    "for i, pattern in enumerate(patterns):\n",
    "    print(f\"Pattern {i+1}: {pattern}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pypremise (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
